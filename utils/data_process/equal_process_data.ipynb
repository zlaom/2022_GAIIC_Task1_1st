{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里的equal process是针对于已经分词后的文件处理的\n",
    "# 1.创建equal_dict，用来替换的字典\n",
    "# 2.使用'title_split'分段，发现equal_dict中的key属性即在title中进行替换\n",
    "# 3.'拉链'分为'裤拉链' '鞋拉链' '拉链'，'系带'分为'裤系带' '鞋系带' '系带'\n",
    "# 4.同时重新处理title为统一大写，只需要将替换后的'title_split'合并即可\n",
    "# 5.重新生成新的合并后的processed_word_dict，并重新生成'vocab_split'分段\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "import json\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_dict = {'半高领': '高领',\n",
    " '立领': '高领',\n",
    " '可脱卸帽': '连帽',\n",
    " '衬衫领': '翻领',\n",
    " 'POLO领': '翻领',\n",
    " '方领': '翻领',\n",
    " '娃娃领': '翻领',\n",
    " '荷叶领': '翻领',\n",
    " '五分袖': '短袖',\n",
    " '九分袖': '长袖',\n",
    " '超短款': '短款',\n",
    " '常规款': '短款',\n",
    " '超长款': '长款',\n",
    " '标准型': '修身型',\n",
    " '超短裙': '短裙',\n",
    " '中长裙': '中裙', \n",
    " 'O型裤': '哈伦裤',\n",
    " '灯笼裤': '哈伦裤',\n",
    " '锥形裤': '哈伦裤',\n",
    " '铅笔裤': '直筒裤',\n",
    " '小脚裤': '直筒裤',\n",
    " '微喇裤': '喇叭裤',\n",
    " '九分裤': '长裤',\n",
    " '套筒': '一脚蹬',\n",
    " '套脚': '一脚蹬',\n",
    " '中帮': '高帮'}\n",
    "# 替换的工作要额外做一个，中长款替换为中款！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载原始的属性字典\n",
    "def load_attr_dict(file):\n",
    "    # 读取属性字典\n",
    "    with open(file, 'r') as f:\n",
    "        attr_dict = {}\n",
    "        for attr, attrval_list in json.load(f).items():\n",
    "            attrval_list = list(map(lambda x: x.split('='), attrval_list))\n",
    "            attr_dict[attr] = list(itertools.chain.from_iterable(attrval_list))\n",
    "    return attr_dict\n",
    "\n",
    "# load attribute dict\n",
    "attr_dict_file = \"../../data/original_data/attr_to_attrvals.json\"\n",
    "attr_dict = load_attr_dict(attr_dict_file)\n",
    "\n",
    "# 相等替换\n",
    "for query, attrs in attr_dict.items():\n",
    "    attrs = attrs.copy()\n",
    "    for i, attr in enumerate(attrs):\n",
    "        if attr in equal_dict:\n",
    "            attr_dict[query].remove(attr)\n",
    "            \n",
    "# 特殊的几个属性替换\n",
    "for query, attrs in attr_dict.items():\n",
    "    attrs = attrs.copy()\n",
    "    for i, attr in enumerate(attrs):\n",
    "        if query=='衣长' and attr=='中长款':\n",
    "            attr_dict[query][i] = '中款'\n",
    "        if query=='裤门襟' and attr=='拉链':\n",
    "            attr_dict[query][i] = '拉链裤'\n",
    "        if query=='裤门襟' and attr=='系带':\n",
    "            attr_dict[query][i] = '系带裤'\n",
    "        if query=='裤门襟' and attr=='松紧':\n",
    "            attr_dict[query][i] = '松紧裤'\n",
    "        if query=='闭合方式' and attr=='拉链':\n",
    "            attr_dict[query][i] = '拉链鞋'\n",
    "        if query=='闭合方式' and attr=='系带':\n",
    "            attr_dict[query][i] = '系带鞋'\n",
    "\n",
    "# 保存新的属性字典\n",
    "attr_save_file = '../../data/equal_processed_data/attr_to_attrvals.json'\n",
    "with open(attr_save_file, 'w') as f:\n",
    "    json.dump(attr_dict, f, ensure_ascii=False, indent=4)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_file = '../../data/equal_processed_data/attr_to_attrvals.json'\n",
    "with open(attr_file, 'r') as f:\n",
    "    attr_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [fine] 移除年份，统一大写，替换相等属性，替换特殊属性\n",
    "fine_data = '../../data/original_data/train_fine.txt'\n",
    "new_fine_data = '../../data/equal_processed_data/fine50000.txt'\n",
    "\n",
    "rets = []\n",
    "delete_list = ['2017年','2018年','2019年','2020年','2021年','2022年']\n",
    "i = 0\n",
    "with open(fine_data, 'r') as f:\n",
    "    for i, data in enumerate(tqdm(f)):\n",
    "        data = json.loads(data)\n",
    "        title = data['title']\n",
    "        title = title.upper() # 字母统一为大写\n",
    "        for delete_item in delete_list:\n",
    "            title = title.replace(delete_item, '')\n",
    "        data['title'] = title\n",
    "        \n",
    "        rets.append(json.dumps(data, ensure_ascii=False)+'\\n')\n",
    "        \n",
    "        # if i>500:\n",
    "        #     break\n",
    "        # i += 1\n",
    "          \n",
    "with open(new_fine_data, 'w') as f:\n",
    "    f.writelines(rets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3304it [00:03, 889.59it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/haoquan/GAIIC2022/utils/data_process/equal_process.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.16.16.232/home/haoquan/GAIIC2022/utils/data_process/equal_process.ipynb#ch0000003vscode-remote?line=35'>36</a>\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.16.16.232/home/haoquan/GAIIC2022/utils/data_process/equal_process.ipynb#ch0000003vscode-remote?line=36'>37</a>\u001b[0m                 word_dict[word] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.16.16.232/home/haoquan/GAIIC2022/utils/data_process/equal_process.ipynb#ch0000003vscode-remote?line=38'>39</a>\u001b[0m         rets\u001b[39m.\u001b[39mappend(json\u001b[39m.\u001b[39;49mdumps(item, ensure_ascii\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.16.16.232/home/haoquan/GAIIC2022/utils/data_process/equal_process.ipynb#ch0000003vscode-remote?line=40'>41</a>\u001b[0m         \u001b[39m# if i>500:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.16.16.232/home/haoquan/GAIIC2022/utils/data_process/equal_process.ipynb#ch0000003vscode-remote?line=41'>42</a>\u001b[0m         \u001b[39m#     break\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.16.16.232/home/haoquan/GAIIC2022/utils/data_process/equal_process.ipynb#ch0000003vscode-remote?line=42'>43</a>\u001b[0m         \u001b[39m# i += 1\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.16.16.232/home/haoquan/GAIIC2022/utils/data_process/equal_process.ipynb#ch0000003vscode-remote?line=44'>45</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(save_file, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/json/__init__.py:234\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    <a href='file:///home/haoquan/miniconda3/lib/python3.9/json/__init__.py?line=231'>232</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/haoquan/miniconda3/lib/python3.9/json/__init__.py?line=232'>233</a>\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONEncoder\n\u001b[0;32m--> <a href='file:///home/haoquan/miniconda3/lib/python3.9/json/__init__.py?line=233'>234</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(\n\u001b[1;32m    <a href='file:///home/haoquan/miniconda3/lib/python3.9/json/__init__.py?line=234'>235</a>\u001b[0m     skipkeys\u001b[39m=\u001b[39;49mskipkeys, ensure_ascii\u001b[39m=\u001b[39;49mensure_ascii,\n\u001b[1;32m    <a href='file:///home/haoquan/miniconda3/lib/python3.9/json/__init__.py?line=235'>236</a>\u001b[0m     check_circular\u001b[39m=\u001b[39;49mcheck_circular, allow_nan\u001b[39m=\u001b[39;49mallow_nan, indent\u001b[39m=\u001b[39;49mindent,\n\u001b[1;32m    <a href='file:///home/haoquan/miniconda3/lib/python3.9/json/__init__.py?line=236'>237</a>\u001b[0m     separators\u001b[39m=\u001b[39;49mseparators, default\u001b[39m=\u001b[39;49mdefault, sort_keys\u001b[39m=\u001b[39;49msort_keys,\n\u001b[1;32m    <a href='file:///home/haoquan/miniconda3/lib/python3.9/json/__init__.py?line=237'>238</a>\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\u001b[39m.\u001b[39;49mencode(obj)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/json/encoder.py:199\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    <a href='file:///home/haoquan/miniconda3/lib/python3.9/json/encoder.py?line=194'>195</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m encode_basestring(o)\n\u001b[1;32m    <a href='file:///home/haoquan/miniconda3/lib/python3.9/json/encoder.py?line=195'>196</a>\u001b[0m \u001b[39m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/haoquan/miniconda3/lib/python3.9/json/encoder.py?line=196'>197</a>\u001b[0m \u001b[39m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/haoquan/miniconda3/lib/python3.9/json/encoder.py?line=197'>198</a>\u001b[0m \u001b[39m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/haoquan/miniconda3/lib/python3.9/json/encoder.py?line=198'>199</a>\u001b[0m chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterencode(o, _one_shot\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    <a href='file:///home/haoquan/miniconda3/lib/python3.9/json/encoder.py?line=199'>200</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(chunks, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[1;32m    <a href='file:///home/haoquan/miniconda3/lib/python3.9/json/encoder.py?line=200'>201</a>\u001b[0m     chunks \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(chunks)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/json/encoder.py:257\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    <a href='file:///home/haoquan/miniconda3/lib/python3.9/json/encoder.py?line=251'>252</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/haoquan/miniconda3/lib/python3.9/json/encoder.py?line=252'>253</a>\u001b[0m     _iterencode \u001b[39m=\u001b[39m _make_iterencode(\n\u001b[1;32m    <a href='file:///home/haoquan/miniconda3/lib/python3.9/json/encoder.py?line=253'>254</a>\u001b[0m         markers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault, _encoder, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindent, floatstr,\n\u001b[1;32m    <a href='file:///home/haoquan/miniconda3/lib/python3.9/json/encoder.py?line=254'>255</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkey_separator, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem_separator, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msort_keys,\n\u001b[1;32m    <a href='file:///home/haoquan/miniconda3/lib/python3.9/json/encoder.py?line=255'>256</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mskipkeys, _one_shot)\n\u001b[0;32m--> <a href='file:///home/haoquan/miniconda3/lib/python3.9/json/encoder.py?line=256'>257</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _iterencode(o, \u001b[39m0\u001b[39;49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fine \n",
    "file = '../../data/split_word/fine45000.txt'\n",
    "save_file = '../../data/final_processed_data/fine45000.txt'\n",
    "\n",
    "word_dict = {}\n",
    "rets = []\n",
    "with open(file, 'r') as f:\n",
    "    for i, line in enumerate(tqdm(f)):\n",
    "        item = json.loads(line)\n",
    "        title = item['title']\n",
    "        title_split = item['title_split']\n",
    "        \n",
    "        # 替换title_split和title\n",
    "        for n, word in enumerate(title_split):\n",
    "            if word in equal_dict: # 等号替换\n",
    "                title_split[n] = equal_dict[word]\n",
    "            elif word in ['拉链', '系带'] and '裤' in title: # 拉链系带替换\n",
    "                title_split[n] = ''.join(['裤', word])\n",
    "            elif word in ['拉链', '系带'] and '鞋' in title: # 拉链系带替换\n",
    "                title_split[n] = ''.join(['鞋', word])\n",
    "        new_title = ''.join(title_split)\n",
    "        item['title'] = new_title\n",
    "        item['title_split'] = title_split\n",
    "        \n",
    "        # 替换key_attr\n",
    "        key_attr = item['key_attr']\n",
    "        for query, attr in key_attr.items():\n",
    "            if attr in equal_dict:\n",
    "                key_attr[query] = equal_dict[attr]\n",
    "                \n",
    "            \n",
    "        # 统计word_dict\n",
    "        for word in title_split:\n",
    "            if word in word_dict:\n",
    "                word_dict[word] += 1\n",
    "            else:\n",
    "                word_dict[word] = 1\n",
    "        \n",
    "        rets.append(json.dumps(item, ensure_ascii=False)+'\\n')\n",
    "        \n",
    "        # if i>500:\n",
    "        #     break\n",
    "        # i += 1\n",
    "        \n",
    "with open(save_file, 'w') as f:\n",
    "    f.writelines(rets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coarse\n",
    "file = '../../data/split_word/coarse89588.txt'\n",
    "save_file = '../../data/final_processed_data/coarse89588.txt'\n",
    "\n",
    "word_dict = {}\n",
    "rets = []\n",
    "with open(file, 'r') as f:\n",
    "    for i, line in enumerate(tqdm(f)):\n",
    "        item = json.loads(line)\n",
    "        title = item['title']\n",
    "        title_split = item['title_split']\n",
    "        \n",
    "        # 替换title_split和title\n",
    "        for n, word in enumerate(title_split):\n",
    "            if word in equal_dict: # 等号替换\n",
    "                title_split[n] = equal_dict[word]\n",
    "            elif word in ['拉链', '系带'] and '裤' in title: # 拉链系带替换\n",
    "                title_split[n] = ''.join(['裤', word])\n",
    "            elif word in ['拉链', '系带'] and '鞋' in title: # 拉链系带替换\n",
    "                title_split[n] = ''.join(['鞋', word])\n",
    "        new_title = ''.join(title_split)\n",
    "        item['title'] = new_title\n",
    "        item['title_split'] = title_split\n",
    "        \n",
    "        # 替换key_attr\n",
    "        key_attr = item['key_attr']\n",
    "        for query, attr in key_attr.items():\n",
    "            if attr in equal_dict:\n",
    "                key_attr[query] = equal_dict[attr]\n",
    "                \n",
    "            \n",
    "        # 统计word_dict\n",
    "        for word in title_split:\n",
    "            if word in word_dict:\n",
    "                word_dict[word] += 1\n",
    "            else:\n",
    "                word_dict[word] = 1\n",
    "        \n",
    "        rets.append(json.dumps(item, ensure_ascii=False)+'\\n')\n",
    "        \n",
    "        # if i>500:\n",
    "        #     break\n",
    "        # i += 1\n",
    "        \n",
    "with open(save_file, 'w') as f:\n",
    "    f.writelines(rets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'春季': 50,\n",
       " '喇叭裤': 1,\n",
       " '牛仔裤': 12,\n",
       " '蓝色': 24,\n",
       " '常规': 100,\n",
       " '厚度': 100,\n",
       " '长裤': 64,\n",
       " '女装': 156,\n",
       " '浅咖': 1,\n",
       " '修身型': 156,\n",
       " '套头': 44,\n",
       " '针织衫': 18,\n",
       " '宽松型': 62,\n",
       " '牛仔蓝': 1,\n",
       " '高领': 36,\n",
       " '长袖': 112,\n",
       " '外套': 14,\n",
       " '纯色': 88,\n",
       " '秋季': 117,\n",
       " '加厚': 54,\n",
       " '灰色': 39,\n",
       " '童装': 46,\n",
       " '衬衫': 15,\n",
       " '短款': 93,\n",
       " '休闲': 34,\n",
       " '百搭': 22,\n",
       " '男士': 69,\n",
       " '棉服': 26,\n",
       " '拉链': 43,\n",
       " '中长款': 63,\n",
       " '翻领': 48,\n",
       " '男装': 149,\n",
       " '微弹': 16,\n",
       " '黑色': 132,\n",
       " '冬季': 92,\n",
       " '裤系带': 7,\n",
       " '字母': 1,\n",
       " '加绒': 26,\n",
       " '裤': 12,\n",
       " '墨绿': 2,\n",
       " '夏季': 39,\n",
       " 'T恤': 35,\n",
       " '短袖': 33,\n",
       " '薄款': 28,\n",
       " '白色': 32,\n",
       " '正装裤': 6,\n",
       " '直筒裤': 34,\n",
       " '长款': 9,\n",
       " '女士': 76,\n",
       " '风衣': 16,\n",
       " '单排扣': 14,\n",
       " '卡其色': 7,\n",
       " '连帽': 46,\n",
       " '印花': 7,\n",
       " '儿童': 17,\n",
       " '酒红色': 6,\n",
       " '仿皮': 16,\n",
       " '皮衣': 30,\n",
       " '暗扣': 2,\n",
       " '羊毛衫': 13,\n",
       " 'V领': 17,\n",
       " '鞋系带': 58,\n",
       " '运动': 14,\n",
       " '帆布鞋': 14,\n",
       " '低帮': 39,\n",
       " '轻便': 6,\n",
       " '卫衣': 19,\n",
       " '圆领': 46,\n",
       " '真皮': 12,\n",
       " '透气': 15,\n",
       " '登山鞋': 10,\n",
       " '高帮': 37,\n",
       " '休闲裤': 24,\n",
       " '毛呢大衣': 23,\n",
       " '西装领': 30,\n",
       " '松紧': 2,\n",
       " 'POLO衫': 14,\n",
       " '条纹': 4,\n",
       " '黑白': 4,\n",
       " '一脚蹬': 5,\n",
       " '户外': 21,\n",
       " '工装鞋': 15,\n",
       " '绿色': 6,\n",
       " '毛衣': 6,\n",
       " '中裙': 2,\n",
       " '连衣裙': 4,\n",
       " '藏蓝色': 1,\n",
       " '浅咖色': 1,\n",
       " '藏青': 4,\n",
       " '牛津布': 1,\n",
       " '精品': 8,\n",
       " '男包': 8,\n",
       " '单肩包': 8,\n",
       " '黑金色': 2,\n",
       " '打底衫': 15,\n",
       " '红色': 11,\n",
       " '粉色': 10,\n",
       " '围巾领': 3,\n",
       " '雪纺衫': 8,\n",
       " '篮球鞋': 8,\n",
       " '棒球领': 6,\n",
       " '七分袖': 3,\n",
       " '拼色': 5,\n",
       " '黄色': 9,\n",
       " '日常': 2,\n",
       " '休闲鞋': 23,\n",
       " '裤拉链': 9,\n",
       " '哈伦裤': 13,\n",
       " '秋': 7,\n",
       " '冬': 7,\n",
       " '运动鞋': 1,\n",
       " '卫裤': 7,\n",
       " '斜挎包': 5,\n",
       " '开衫': 12,\n",
       " '时尚': 7,\n",
       " '潮流': 7,\n",
       " '皮草': 10,\n",
       " '米蓝': 1,\n",
       " '板鞋': 2,\n",
       " '山羊绒': 4,\n",
       " '浅灰色': 4,\n",
       " '羊绒衫': 12,\n",
       " '蔷薇': 1,\n",
       " '绿': 1,\n",
       " '白': 6,\n",
       " '黑': 7,\n",
       " '米白色': 7,\n",
       " '弹力': 1,\n",
       " '米色': 4,\n",
       " '商务': 14,\n",
       " '公文包': 6,\n",
       " '棕色': 3,\n",
       " '牛皮': 6,\n",
       " '羊毛': 7,\n",
       " '西瓜': 1,\n",
       " '红': 1,\n",
       " '图片': 1,\n",
       " '色': 1,\n",
       " '三粒扣': 1,\n",
       " '格子灰色': 1,\n",
       " '砖红': 1,\n",
       " '阔腿裤': 5,\n",
       " '桔色': 3,\n",
       " '厚款': 8,\n",
       " '夹克': 12,\n",
       " '咖色': 5,\n",
       " '中灰': 2,\n",
       " '米白': 2,\n",
       " '双肩包': 1,\n",
       " '运动包': 2,\n",
       " '马甲': 14,\n",
       " '卡其': 3,\n",
       " '浅卡其色': 1,\n",
       " '短外套': 4,\n",
       " '上青': 1,\n",
       " '浅蓝色': 1,\n",
       " '金黄': 1,\n",
       " '羽绒服': 19,\n",
       " '孔雀蓝': 2,\n",
       " '上衣': 1,\n",
       " '墨绿色': 2,\n",
       " '浅蓝': 3,\n",
       " '紫色': 1,\n",
       " '深蓝': 4,\n",
       " '灰': 3,\n",
       " '格子': 8,\n",
       " '手提包': 2,\n",
       " '增高': 2,\n",
       " '无弹力': 2,\n",
       " '卡迪驼': 1,\n",
       " '卡通': 8,\n",
       " '动漫': 8,\n",
       " '杏色': 7,\n",
       " '大红': 1,\n",
       " '保暖': 1,\n",
       " '运动裤': 11,\n",
       " '服饰': 7,\n",
       " '大衣': 4,\n",
       " '白鸭绒': 4,\n",
       " '2016年': 1,\n",
       " '浅灰': 1,\n",
       " '杏白': 1,\n",
       " '3D': 4,\n",
       " '湖蓝色': 2,\n",
       " '豆沙紫': 1,\n",
       " '无袖': 1,\n",
       " '金驼色': 1,\n",
       " '蓝': 5,\n",
       " '虾青': 1,\n",
       " '松紧带': 1,\n",
       " '灰白色': 2,\n",
       " '中蓝色': 1,\n",
       " '酒红': 2,\n",
       " '弹力宝蓝色': 1,\n",
       " '绅士': 8,\n",
       " '耐磨': 6,\n",
       " '橘红色': 1,\n",
       " '粉红色': 3,\n",
       " '稚嫩': 1,\n",
       " '粉': 2,\n",
       " '双排扣': 3,\n",
       " '深米色': 1,\n",
       " '系带': 3,\n",
       " '防滑': 3,\n",
       " '靴子': 2,\n",
       " '上青色': 1,\n",
       " '创意': 1,\n",
       " '趣味': 1,\n",
       " '复古蓝': 1,\n",
       " '桃红色': 1,\n",
       " '防水': 3,\n",
       " '短裙': 1,\n",
       " '无扣': 3,\n",
       " '黄': 2,\n",
       " '驼色': 3,\n",
       " '帆布': 1,\n",
       " '咖啡': 1,\n",
       " '轻薄': 1,\n",
       " 'U型领': 1,\n",
       " '标准': 1,\n",
       " '五分裤': 1,\n",
       " '橙色': 1,\n",
       " '蔚蓝色': 1,\n",
       " '黑金': 1,\n",
       " '米黑色': 1,\n",
       " '咖啡色': 4,\n",
       " '衬衣': 3,\n",
       " '豆绿': 1,\n",
       " '灰蓝': 1,\n",
       " '藏蓝': 1,\n",
       " '哈青': 1,\n",
       " '白兰': 1,\n",
       " '焦糖': 1,\n",
       " '背心': 1,\n",
       " '蔚蓝': 1,\n",
       " '手绘': 1,\n",
       " '头层': 1,\n",
       " '雨鞋': 1,\n",
       " '灰粉色': 1,\n",
       " '裤子': 1,\n",
       " '深棕色': 1,\n",
       " '速干': 1,\n",
       " '水蓝色': 1,\n",
       " '暗灰色': 1,\n",
       " '藏青色': 1,\n",
       " '灰绿色': 1,\n",
       " '深灰': 1,\n",
       " '深灰色': 1,\n",
       " '减震': 3,\n",
       " '紫': 2,\n",
       " '深蓝色': 4,\n",
       " '杏': 1,\n",
       " '蓝灰': 1,\n",
       " '棉衣': 1,\n",
       " '孔雀色': 1,\n",
       " '春': 3,\n",
       " '夏': 3,\n",
       " '米黄': 1,\n",
       " '燕麦色': 1,\n",
       " '抗冲击': 1,\n",
       " '往季': 1,\n",
       " '沙色': 1,\n",
       " '灰鸭绒': 1,\n",
       " '沉绿': 1,\n",
       " '桃红': 1,\n",
       " '果绿色': 1,\n",
       " '堆堆领': 1,\n",
       " '豆绿色': 1,\n",
       " '鸭绒': 1,\n",
       " '永恒': 1,\n",
       " '春夏': 1,\n",
       " '防护': 1,\n",
       " '深宝蓝': 1}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a7cf278074aea429de13d88b394304564a7b018f3e18e13089daf4fad90abe0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
