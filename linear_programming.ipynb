{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from scipy.stats import entropy\n",
    "import math\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_entropy(p, num_list):\n",
    "    S = sum(num_list)\n",
    "    N = len(num_list)\n",
    "    Entropy = 0\n",
    "    num_list_aft = []\n",
    "    for n in num_list:\n",
    "        n_pos = n*(1-p)\n",
    "        n_neg = (S-n)*p/(N-1)\n",
    "        n_tol = n_pos + n_neg\n",
    "        num_list_aft.append(n_tol)\n",
    "        P_pos = n_pos / n_tol\n",
    "        P_neg = n_neg / n_tol\n",
    "        Ei = - P_pos * math.log(P_pos, 2) - P_neg * math.log(P_neg, 2)\n",
    "        Pi = n / S # proba\n",
    "        # Pi = math.exp(Pi*1.17)\n",
    "        # print(Pi)\n",
    "        Entropy = Entropy + Pi * Ei\n",
    "        \n",
    "    p_ori = np.array(num_list) / S\n",
    "    p_aft = np.array(num_list_aft) / S\n",
    "    KL_div = entropy(p_ori, p_aft)\n",
    "    \n",
    "    return -Entropy\n",
    "\n",
    "def info_entropy_v2(P_list, Proba_matrix, num_list):\n",
    "    S = sum(num_list)\n",
    "    N = len(num_list)\n",
    "    num_list_aft = []\n",
    "    Entropy = 0\n",
    "    for i in range(N): # 一共N个数据\n",
    "        p = P_list[i]\n",
    "        n = num_list[i]\n",
    "        n_pos = n*(1-p) # 正例个数\n",
    "        n_neg = 0\n",
    "        for j in range(N):\n",
    "            if j != i:\n",
    "                n_other = num_list[j]\n",
    "                p_neg = P_list[j]\n",
    "                proba = Proba_matrix[j, i] # 第j个属性生成第i个属性的概率\n",
    "                n_neg += n_other * p_neg * proba # 其他属性，每个生成负例的个数乘以生成i属性的概率\n",
    "        n_tol = n_pos + n_neg\n",
    "        num_list_aft.append(n_tol)\n",
    "        P_pos = n_pos / n_tol\n",
    "        P_neg = n_neg / n_tol\n",
    "        Ei = - P_pos * math.log(P_pos, 2) - P_neg * math.log(P_neg, 2)\n",
    "        Pi = n / S # proba\n",
    "        # print(Pi)\n",
    "        Entropy = Entropy + Ei\n",
    "        \n",
    "    # 还要约束比例前后尽可能一致，用KL散度衡量前后分布的一致性\n",
    "    p_ori = np.array(num_list) / S\n",
    "    p_aft = np.array(num_list_aft) / S\n",
    "    KL_div = entropy(p_ori, p_aft)\n",
    "    \n",
    "    return -Entropy + KL_div\n",
    "    # return -Entropy + 0.5 * KL_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4625358 0.3       0.3       0.3      ]\n"
     ]
    }
   ],
   "source": [
    "num_list = [6122, 34906, 418, 747]\n",
    "# num_list = [843, 1738, 633, 913]\n",
    "N = len(num_list)\n",
    "P_list = [0.5] * N\n",
    "Proba_matrix = np.ones([N, N]) / (N-1)\n",
    "pmax = 0.7; pmin = 0.3\n",
    "\n",
    "def makefunmin(i, pmin):\n",
    "    return lambda x: x[i]-pmin\n",
    "def makefunmax(i, pmax):\n",
    "    return lambda x: pmax-x[i]\n",
    "cons = ()\n",
    "for i in range(N):\n",
    "    cons = cons +({'type': 'ineq', 'fun': makefunmin(i, pmin)},\n",
    "                  {'type': 'ineq', 'fun': makefunmax(i, pmax)},)\n",
    "    \n",
    "\n",
    "p = minimize(info_entropy_v2, P_list, args=(Proba_matrix, num_list), constraints=cons, method='SLSQP')\n",
    "print(p.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_list = [0.5, 0.5, 0.5, 0.5]\n",
    "num_list = [6122,6122,6122,747]\n",
    "# num_list = [100, 100, 100, 100]\n",
    "N = len(num_list)\n",
    "Proba_matrix = np.ones([N, N]) / (N-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = [0.5]\n",
    "num_list = [6122,34906,418,747]\n",
    "cons = ({'type': 'ineq', 'fun': lambda x: np.array([x[0]-0.01])},\n",
    "        {'type': 'ineq', 'fun': lambda x: np.array([0.99-x[0]])})\n",
    "p = minimize(info_entropy, p0, args=(num_list), constraints=cons, method='SLSQP')\n",
    "print(p.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "attr_dict_file = 'data/equal_processed_data/attr_to_attrvals.json'\n",
    "vocab_dict_file = 'dataset/vocab/vocab_dict.json'\n",
    "with open(attr_dict_file, 'r') as f:\n",
    "    attr_dict = json.load(f)\n",
    "with open(vocab_dict_file, 'r') as f:\n",
    "    vocab_dict = json.load(f)\n",
    "def get_negative_dict(attr_dict, vocab_dict):\n",
    "    proba_negative_dict = {}\n",
    "    for query, attr_list in attr_dict.items():\n",
    "        proba_negative_dict[query] = {}\n",
    "        proba_negative_dict[query]['attr_list'] = attr_list\n",
    "        proba_list = []\n",
    "        for attr in attr_list:\n",
    "            proba_list.append(vocab_dict[attr])\n",
    "        proba_negative_dict[query]['attr_freq'] = proba_list\n",
    "            \n",
    "    return proba_negative_dict\n",
    "\n",
    "proba_negative_dict = get_negative_dict(attr_dict, vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy \n",
    "from scipy.optimize import minimize\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# 每个query统一一个概率p\n",
    "# dict_copy = copy.deepcopy(proba_negative_dict)\n",
    "# for query, attr_dict in dict_copy.items():\n",
    "#      num_list = attr_dict['attr_freq']\n",
    "#      p0 = [0.5] # 注意函数p是负例生成概率\n",
    "#      cons = ({'type': 'ineq',\n",
    "#           'fun': lambda x: np.array([x[0]-0.01]),\n",
    "#           'jac': lambda x: np.array([1.0])},\n",
    "#           {'type': 'ineq',\n",
    "#           'fun': lambda x: np.array([0.99-x[0]]),\n",
    "#           'jac': lambda x: np.array([-1.0])})\n",
    "#      p = minimize(info_entropy, p0, args=(num_list), constraints=cons, method='SLSQP')\n",
    "#      proba_negative_dict[query]['entropy_proba'] = p.x.item()\n",
    "\n",
    "\n",
    "# 每个attr一个概率p\n",
    "dict_copy = copy.deepcopy(proba_negative_dict)\n",
    "for query, attr_dict in dict_copy.items():\n",
    "     num_list = attr_dict['attr_freq']\n",
    "     N = len(num_list)\n",
    "     P_list = [0.5] * N\n",
    "     Proba_matrix = np.ones([N, N]) / (N-1)\n",
    "     pmax = 0.7; pmin = 0.3\n",
    "     \n",
    "     def makefunmin(i, pmin):\n",
    "        return lambda x: x[i]-pmin\n",
    "     def makefunmax(i, pmax):\n",
    "          return lambda x: pmax-x[i]\n",
    "     cons = ()\n",
    "     for i in range(N):\n",
    "          cons = cons +({'type': 'ineq', 'fun': makefunmin(i, pmin)},\n",
    "                         {'type': 'ineq', 'fun': makefunmax(i, pmax)},)\n",
    "    \n",
    "     p = minimize(info_entropy_v2, P_list, args=(Proba_matrix, num_list), constraints=cons, method='SLSQP')\n",
    "     proba_negative_dict[query]['entropy_proba'] = p.x.tolist()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_save_file = 'data/equal_processed_data/proba_negative_dict_independent.json'\n",
    "with open(attr_save_file, 'w') as f:\n",
    "    json.dump(proba_negative_dict, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
