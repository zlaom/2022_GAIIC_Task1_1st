{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('./data/fl_equal_split_word/title/order_fine9000.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "print(len(lines))\n",
    "\n",
    "save_path_1 = './data/fl_equal_split_word/title/order_fine3000_1.txt'\n",
    "save_path_2 = './data/fl_equal_split_word/title/order_fine3000_2.txt'\n",
    "save_path_3 = './data/fl_equal_split_word/title/order_fine3000_3.txt'\n",
    "with open(save_path_1, 'w') as f:\n",
    "    f.writelines(lines[:3000])\n",
    "with open(save_path_2, 'w') as f:\n",
    "    f.writelines(lines[3000:6000])\n",
    "with open(save_path_3, 'w') as f:\n",
    "    f.writelines(lines[6000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data_list = []\n",
    "\n",
    "with open('data/fl_split_word/coarse10412.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        data = json.loads(line)\n",
    "        del data['feature']\n",
    "        data_list.append(json.dumps(data, ensure_ascii=False)+'\\n')\n",
    "\n",
    "with open('data/fl_split_word/just_title_coarse10412.txt', 'w') as f:\n",
    "    f.writelines(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def print_dis_match(attrs, title):\n",
    "    flag = True\n",
    "    for attr in attrs:\n",
    "        if attr in title:\n",
    "            flag = False\n",
    "            break\n",
    "    if flag:\n",
    "        print(title)\n",
    "    return flag\n",
    "\n",
    "data_list = []\n",
    "\n",
    "with open('data/fl_split_word/just_title_coarse10412.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        data = json.loads(line)\n",
    "        title = data['title']\n",
    "        if '领' in title:\n",
    "            attrs = [\"高领\",\"高半领\",\"立领\",\"连帽\",\"可脱卸帽\",\"翻领\",\"衬衫领\",\"POLO领\",\"方领\",\"娃娃领\",\"荷叶领\", \"双层领\", \"西装领\", \"U型领\", \"一字领\",\"围巾领\", \"堆堆领\", \"V领\", \"棒球领\", \"圆领\", \"斜领\", \"亨利领\"]\n",
    "            if print_dis_match(attrs, title):\n",
    "                data_list.append('领     :'+title+'\\n')\n",
    "            \n",
    "        if '袖' in title:\n",
    "            attrs = [\"短袖\",\"五分袖\",\"九分袖\",\"长袖\",\"七分袖\",\"无袖\"]\n",
    "            if print_dis_match(attrs, title):\n",
    "                data_list.append('袖     :'+title+'\\n')\n",
    "        if '款' in title:\n",
    "            attrs = [\"短超款\",\"短款\",\"常规款\",\"长款\",\"长超款\",\"长中款\"]\n",
    "            if print_dis_match(attrs, title):\n",
    "                data_list.append('款     :'+title+'\\n')\n",
    "        if '型' in title:\n",
    "            attrs = [\"修身型\",\"标准型\",\"宽松型\"]\n",
    "            if print_dis_match(attrs, title):\n",
    "                data_list.append('型     :'+title+'\\n')\n",
    "        if '裙' in title:\n",
    "            attrs = [\"短裙\", \"短超裙\", \"中裙\", \"中大裙\", \"长裙\"]\n",
    "            if print_dis_match(attrs, title):\n",
    "                data_list.append('裙     :'+title+'\\n')\n",
    "        if '包' in title:\n",
    "            attrs = [\"手提包\", \"单肩包\", \"斜挎包\", \"双肩包\"]\n",
    "            if print_dis_match(attrs, title):\n",
    "                data_list.append('包     :'+title+'\\n')\n",
    "        if '裤' in title:\n",
    "            attrs = [\"O型裤\", \"锥形裤\",\"哈伦裤\",\"灯笼裤\", \"铅笔裤\",\"直筒裤\",\"小脚裤\", \"工装裤\",\"紧身裤\",\"背带裤\",\"喇叭裤\",\"微喇裤\",\"阔腿裤\",\"短裤\",\"五分裤\",\"七分裤\",\"九分裤\",\"长裤\",\"松紧裤\",\"拉链裤\",\"系带裤\"]\n",
    "            if print_dis_match(attrs, title):\n",
    "                data_list.append('裤     :'+title+'\\n')\n",
    "print(len(data_list))\n",
    "with open('./data/fl_split_word/coarse_neg_attr.txt', 'w') as f:\n",
    "    f.writelines(data_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.6526,  1.2047,  1.3615,  1.3686],\n",
      "         [-0.9293, -2.9328,  1.6652,  0.6390],\n",
      "         [-0.8360,  0.9453,  1.0863, -0.8769]],\n",
      "\n",
      "        [[-1.3161,  2.5320, -1.6704,  1.3836],\n",
      "         [ 0.0116, -0.8137,  0.4447, -0.4149],\n",
      "         [ 0.4616,  0.1535,  1.0793,  1.2736]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.randn(2,3,4)\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False,  True])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([0, 1])\n",
    "b = torch.tensor([1, 1])\n",
    "c = torch.eq(a, b) # False\n",
    "d = torch.eq(b, b) # True\n",
    "\n",
    "e = c & d\n",
    "print(e) # False"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6b82eb5136476e726054b37d23634d2c7704283ad933f76ee90fc6ec02ce148f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
