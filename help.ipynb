{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,4,3,4]\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "attr_dict_file = 'dataset/vocab/word_dict.json'\n",
    "with open(attr_dict_file, 'r') as f:\n",
    "    attr_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'无拉链'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/haoquan/GAIIC2022/help.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.16.16.232/home/haoquan/GAIIC2022/help.ipynb#ch0000038vscode-remote?line=0'>1</a>\u001b[0m attr_dict[\u001b[39m'\u001b[39;49m\u001b[39m无拉链\u001b[39;49m\u001b[39m'\u001b[39;49m]\n",
      "\u001b[0;31mKeyError\u001b[0m: '无拉链'"
     ]
    }
   ],
   "source": [
    "attr_dict['无拉链']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.tensor([i for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm \n",
    "import json \n",
    "import torch \n",
    "\n",
    "class TitleDataset(Dataset):\n",
    "    def __init__(self, input_filename, is_train):\n",
    "        self.is_train = is_train\n",
    "        self.items = []\n",
    "        for file in input_filename.split(','):\n",
    "            with open(file, 'r') as f:\n",
    "                for line in tqdm(f):\n",
    "                    item = json.loads(line)\n",
    "                    if self.is_train:\n",
    "                        if item['match']['图文']: # 训练集图文必须匹配\n",
    "                            self.items.append(item)\n",
    "                    else:\n",
    "                        self.items.append(item)\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.items)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = torch.tensor(self.items[idx]['feature'])\n",
    "        words = self.items[idx]['vocab_split']\n",
    "        if self.is_train:\n",
    "            return image, words\n",
    "        else:\n",
    "            label = self.items[idx]['match']['图文']\n",
    "            return image, title, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    tensors = []\n",
    "    splits = []\n",
    "    for feature, split in batch:\n",
    "        tensors.append(feature)\n",
    "        splits.append(split)\n",
    "    tensors = torch.stack(tensors)\n",
    "    return tensors, splits\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "502it [00:00, 3186.77it/s]\n"
     ]
    }
   ],
   "source": [
    "train_file = 'data/split_word/fine500_sample.txt'\n",
    "train_dataset = TitleDataset(train_file, is_train=True)\n",
    "train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=3,\n",
    "        shuffle=True,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "        collate_fn=collate_fn,\n",
    "        drop_last=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.1288, 0.0095, 0.0517,  ..., 0.4841, 1.4008, 1.3691]),\n",
       " ['春季', '微喇裤', '牛仔裤', '蓝色', '常规', '厚度', '九分裤', '女装'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2048])\n",
      "[['单肩包', '休闲', '运动包', '黑色'], ['休闲', '系带', '高帮', '男士', '帆布鞋', '秋季', '白', '黑', '卡通', '动漫'], ['翻领', '灰色', '常规', '厚度', '短款', '男装', '男士', '夹克', '标准型']]\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    features, splits = batch\n",
    "    print(features.shape)\n",
    "    print(splits)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = iter(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.9584,  0.0069,  0.0213,  ..., -1.3852,  0.9849, -0.0526],\n",
       "         [-0.0550,  0.0022,  0.0114,  ..., -0.7029, -1.3373,  1.3214],\n",
       "         [-0.2397, -0.0084,  0.0152,  ..., -0.3304,  0.3013,  1.2746]]),\n",
       " [['加厚', '连帽', '中长款', '大衣', '秋季', '蓝色', '拉链', '童装'],\n",
       "  ['黑色', '秋季', '马甲', '标准型', '常规', '厚度', '开衫', '男装'],\n",
       "  ['白色', '短袖', '衬衫', '秋季', '纯色', '童装']]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def get_negative_dict(file):\n",
    "    with open(file, 'r') as f:\n",
    "        new_dict = {}\n",
    "        for attr, attrval_list in json.load(f).items():\n",
    "            attr_dict = {}\n",
    "            new_dict[attr] = attr_dict\n",
    "            for x in attrval_list:\n",
    "                l = attrval_list.copy()\n",
    "                l.remove(x)\n",
    "                x = x.split('=')\n",
    "                l_noequal = list(map(lambda x: x.split('='), l))\n",
    "                for k in x:\n",
    "                    attr_dict[k] = list(itertools.chain.from_iterable(l_noequal))\n",
    "    return new_dict\n",
    "\n",
    "attr_dict_file = \"data/original_data/attr_to_attrvals.json\"\n",
    "negative_dict = get_negative_dict(attr_dict_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([0.1,0.4,0.5])\n",
    "np.random.choice([1,2,3], p=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "all_keys = list(ckpt.keys())\n",
    "new_dict = OrderedDict()\n",
    "for key in all_keys:\n",
    "    if key.startswith('attr_encoder.'):\n",
    "        new_dict[key[13:]] = ckpt[key]\n",
    "    else:\n",
    "        new_dict[key] = ckpt[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import torch \n",
    "import json\n",
    "import numpy as np \n",
    "import random \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm \n",
    "\n",
    "from model.attribute_matching import AttrModel\n",
    "\n",
    "\n",
    "# 用来生成负样本的字典\n",
    "def get_negative_dict(file):\n",
    "    with open(file, 'r') as f:\n",
    "        new_dict = {}\n",
    "        for attr, attrval_list in json.load(f).items():\n",
    "            attr_dict = {}\n",
    "            new_dict[attr] = attr_dict\n",
    "            for x in attrval_list:\n",
    "                l = attrval_list.copy()\n",
    "                l.remove(x)\n",
    "                x = x.split('=')\n",
    "                l_noequal = list(map(lambda x: x.split('='), l))\n",
    "                for k in x:\n",
    "                    attr_dict[k] = list(itertools.chain.from_iterable(l_noequal))\n",
    "    return new_dict\n",
    "\n",
    "attr_dict_file = \"data/original_data/attr_to_attrvals.json\"\n",
    "negative_dict = get_negative_dict(attr_dict_file)\n",
    "\n",
    "# 用来生成正样本的数据增强字典\n",
    "def get_positive_dict(file):\n",
    "    with open(file, 'r') as f:\n",
    "        new_dict = {}\n",
    "        for attr, attrval_list in json.load(f).items():\n",
    "            attr_dict = {}\n",
    "            new_dict[attr] = attr_dict\n",
    "            for x in attrval_list:\n",
    "                x = x.split('=')\n",
    "                for k in x:\n",
    "                    attr_dict[k] = x\n",
    "    return new_dict\n",
    "attr_dict_file = \"data/original_data/attr_to_attrvals.json\"\n",
    "positive_dict = get_positive_dict(attr_dict_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import itertools\n",
    "import tqdm\n",
    "\n",
    "def load_attr_dict(file):\n",
    "    # 读取属性字典\n",
    "    with open(file, 'r') as f:\n",
    "        attr_dict = {}\n",
    "        for attr, attrval_list in json.load(f).items():\n",
    "            attrval_list = list(map(lambda x: x.split('='), attrval_list))\n",
    "            attr_dict[attr] = list(itertools.chain.from_iterable(attrval_list))\n",
    "    return attr_dict\n",
    "\n",
    "def match_attrval(title, attr, attr_dict):\n",
    "    # 在title中匹配属性值\n",
    "    attrvals = \"|\".join(attr_dict[attr])\n",
    "    ret = re.findall(attrvals, title)\n",
    "    # return \"{}{}\".format(attr, ''.join(ret))\n",
    "    return \"{}\".format(''.join(ret))  \n",
    "\n",
    "attr_dict_file = \"data/original_data/attr_to_attrvals.json\"\n",
    "attr_dict = load_attr_dict(attr_dict_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'松紧松紧'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = '松紧带抓鸡松紧'\n",
    "match_attrval(title, '裤门襟', attr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'松紧带抓鸡松紧'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'拉链带抓鸡拉链'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title.replace('松紧', '拉链')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltp import LTP\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltp = LTP(path='base') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取得属性字典并添加到词表\n",
    "def get_dict(file):\n",
    "    with open(file, 'r') as f:\n",
    "        all_attr = []\n",
    "        for attr, attrval_list in json.load(f).items():\n",
    "            for x in attrval_list:\n",
    "                x = x.split('=')\n",
    "                for k in x:\n",
    "                    all_attr.append(k)\n",
    "    return all_attr\n",
    "attr_dict_file = \"data/original_data/attr_to_attrvals.json\"\n",
    "all_attr = get_dict(attr_dict_file)\n",
    "extra_words = []\n",
    "extra_words.append(['牛津布', '仿皮', '吸湿', '吸汗', '防滑', '抗冲击', '微弹', '加绒'])\n",
    "extra_words.append(['上青', '上青色', '上青绿', '羊绒衫'])\n",
    "extra_words.append(['休闲鞋', '工装鞋', '男包', '女包', '运动裤', '休闲裤', '加厚领'])\n",
    "extra_words.append(['加厚', '薄款', '厚款', '短款', '短外套'])\n",
    "extra_words.append(['不加绒', '无扣', '无弹力', '无弹', '无拉链'])\n",
    "extra_words.append(['一粒扣', '两粒扣', '暗扣', '三粒扣', '系扣'])\n",
    "extra_words.append(['大红色', '大花'])\n",
    "for extra in extra_words:   \n",
    "    all_attr = all_attr + extra\n",
    "\n",
    "ltp.init_dict(path=\"user_dict.txt\", max_window=6)\n",
    "ltp.add_words(words=all_attr, max_window=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45000it [08:45, 85.65it/s]\n",
      "89588it [17:21, 85.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# 统计训练集的词表和词频\n",
    "fine_file = 'data/train/fine45000.txt'\n",
    "word_dict = {}\n",
    "with open(fine_file, 'r') as f:\n",
    "    for line in tqdm(f):\n",
    "        item = json.loads(line)\n",
    "        segment, _ = ltp.seg([item['title']])\n",
    "        for word in segment[0]:\n",
    "            word = word.upper() # 字母统一为大写\n",
    "            if word in word_dict:\n",
    "                word_dict[word] += 1\n",
    "            else:\n",
    "                word_dict[word] = 1\n",
    "\n",
    "coarse_file = 'data/train/coarse89588.txt'\n",
    "with open(coarse_file, 'r') as f:\n",
    "    for line in tqdm(f):\n",
    "        item = json.loads(line)\n",
    "        segment, _ = ltp.seg([item['title']])\n",
    "        for word in segment[0]:\n",
    "            word = word.upper() # 字母统一为大写\n",
    "            if word in word_dict:\n",
    "                word_dict[word] += 1\n",
    "            else:\n",
    "                word_dict[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为了不丢失花大量时间生成的词表先做一个拷贝\n",
    "import copy \n",
    "copy_dict = copy.deepcopy(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 备用代码\n",
    "# word_dict = copy.deepcopy(copy_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统一大量颜色的别称\n",
    "color_list = ['兰','蓝','灰','绿','粉','红','黄','青','紫','白','黑','骆','橙','杏','咖','棕','啡','褐','银','金','橘','藏']\n",
    "keys = []\n",
    "for key in  word_dict.keys():\n",
    "    keys.append(key)\n",
    "for key in keys:\n",
    "    for i in key:\n",
    "        if i in color_list and word_dict[key] < 50:\n",
    "            if i in word_dict:\n",
    "                word_dict[i] += word_dict[key]\n",
    "            else:\n",
    "                word_dict[i] = word_dict[key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除出现次数少的词\n",
    "keys = []\n",
    "for key in word_dict.keys():\n",
    "    keys.append(key)\n",
    "for key in keys:\n",
    "    if word_dict[key] < 50:\n",
    "        del word_dict[key]\n",
    "    if key == '/':\n",
    "        del word_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存词表\n",
    "with open('word_dict.json', 'w') as f:\n",
    "    json.dump(word_dict, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存处理后的词表\n",
    "with open('processed_word_dict.json', 'w') as f:\n",
    "    json.dump(word_dict, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读入保存的词表\n",
    "with open('processed_word_dict.json', 'r') as f:\n",
    "    processed_word_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'春季': 11663,\n",
       " '微喇裤': 307,\n",
       " '牛仔裤': 4171,\n",
       " '蓝色': 6279,\n",
       " '常规': 26114,\n",
       " '厚度': 24087,\n",
       " '九分裤': 3254,\n",
       " '女装': 47717,\n",
       " '浅咖': 70,\n",
       " '修身型': 20147,\n",
       " '套头': 15191,\n",
       " '针织衫': 6258,\n",
       " '宽松型': 19726,\n",
       " '牛仔蓝': 189,\n",
       " '半高领': 3616,\n",
       " '长袖': 34415,\n",
       " '外套': 6731,\n",
       " '纯色': 25986,\n",
       " '秋季': 32528,\n",
       " '加厚': 16141,\n",
       " '灰色': 7153,\n",
       " '高领': 3727,\n",
       " '童装': 17785,\n",
       " '衬衫': 4284,\n",
       " '常规款': 18123,\n",
       " '休闲': 9649,\n",
       " '百搭': 5344,\n",
       " '男士': 14405,\n",
       " '棉服': 6540,\n",
       " '拉链': 14748,\n",
       " '中长款': 13700,\n",
       " '翻领': 5963,\n",
       " '男装': 37285,\n",
       " '微弹': 4159,\n",
       " '黑色': 32664,\n",
       " '冬季': 23523,\n",
       " '系带': 14200,\n",
       " '字母': 1299,\n",
       " '加绒裤': 3948,\n",
       " '墨绿': 243,\n",
       " '夏季': 8847,\n",
       " '标准型': 15138,\n",
       " 'POLO领': 2249,\n",
       " 'T恤': 6952,\n",
       " '短袖': 5876,\n",
       " '薄款': 6046,\n",
       " '白色': 8428,\n",
       " '正装裤': 1441,\n",
       " '长裤': 14112,\n",
       " '小脚裤': 1134,\n",
       " '立领': 4878,\n",
       " '长款': 1986,\n",
       " '女士': 13116,\n",
       " '风衣': 3717,\n",
       " '单排扣': 4040,\n",
       " '卡其色': 2447,\n",
       " '连帽': 12974,\n",
       " '印花': 1274,\n",
       " '儿童': 5896,\n",
       " '酒红色': 931,\n",
       " '仿皮': 3128,\n",
       " '皮衣': 7039,\n",
       " '娃娃领': 576,\n",
       " '暗扣': 168,\n",
       " '羊毛衫': 2715,\n",
       " 'V领': 3525,\n",
       " '运动': 5232,\n",
       " '帆布鞋': 3086,\n",
       " '低帮': 8997,\n",
       " '轻便': 458,\n",
       " '卫衣': 7387,\n",
       " '圆领': 12853,\n",
       " '真皮': 2684,\n",
       " '透气': 2190,\n",
       " '登山鞋': 1108,\n",
       " '高帮': 4090,\n",
       " '休闲裤': 4541,\n",
       " '毛呢大衣': 3378,\n",
       " '西装领': 4175,\n",
       " '松紧': 832,\n",
       " 'POLO衫': 3143,\n",
       " '条纹': 983,\n",
       " '黑白': 365,\n",
       " '套脚': 966,\n",
       " '户外': 4084,\n",
       " '工装鞋': 1642,\n",
       " '绿色': 2222,\n",
       " '中帮': 1842,\n",
       " '加绒': 5629,\n",
       " '毛衣': 3631,\n",
       " '中长裙': 696,\n",
       " '荷叶领': 290,\n",
       " '连衣裙': 2070,\n",
       " '藏蓝色': 312,\n",
       " '浅咖色': 100,\n",
       " '藏青': 777,\n",
       " '牛津布': 343,\n",
       " '精品': 1389,\n",
       " '男包': 1189,\n",
       " '单肩包': 1738,\n",
       " '打底衫': 3613,\n",
       " '红色': 3243,\n",
       " '短款': 11628,\n",
       " '粉色': 2369,\n",
       " '围巾领': 177,\n",
       " '雪纺衫': 1084,\n",
       " '篮球鞋': 1398,\n",
       " '棒球领': 908,\n",
       " '七分袖': 418,\n",
       " '拼色': 888,\n",
       " '黄色': 1743,\n",
       " '日常': 670,\n",
       " '休闲鞋': 5003,\n",
       " '哈伦裤': 2471,\n",
       " '秋': 1491,\n",
       " '冬': 1448,\n",
       " '运动鞋': 134,\n",
       " '直筒裤': 5567,\n",
       " '卫裤': 1210,\n",
       " '斜挎包': 633,\n",
       " '开衫': 2886,\n",
       " '时尚': 3390,\n",
       " '潮流': 3364,\n",
       " '皮草': 1727,\n",
       " '板鞋': 1153,\n",
       " '山羊绒': 660,\n",
       " '浅灰色': 685,\n",
       " '羊绒衫': 3933,\n",
       " '绿': 1566,\n",
       " '白': 3591,\n",
       " '黑': 3513,\n",
       " '米白色': 1670,\n",
       " '弹力': 693,\n",
       " '米色': 1217,\n",
       " '商务': 3559,\n",
       " '公文包': 1228,\n",
       " '棕色': 1054,\n",
       " '牛皮': 1142,\n",
       " '羊毛': 1485,\n",
       " '红': 1958,\n",
       " '图片': 91,\n",
       " '色': 177,\n",
       " '三粒扣': 152,\n",
       " '砖红': 51,\n",
       " '阔腿裤': 1386,\n",
       " '桔色': 233,\n",
       " '厚': 2225,\n",
       " '款': 3295,\n",
       " '夹克': 2293,\n",
       " '咖色': 653,\n",
       " '中灰': 143,\n",
       " '米白': 695,\n",
       " '双肩包': 913,\n",
       " '运动包': 1395,\n",
       " '马甲': 3400,\n",
       " '卡其': 1006,\n",
       " '铅笔裤': 1110,\n",
       " '短': 1555,\n",
       " '上青': 89,\n",
       " '浅蓝色': 594,\n",
       " '羽绒服': 6989,\n",
       " '孔雀蓝': 122,\n",
       " '上衣': 1831,\n",
       " '墨绿色': 415,\n",
       " '浅蓝': 359,\n",
       " '一脚蹬': 52,\n",
       " '紫色': 1026,\n",
       " '深蓝': 522,\n",
       " '工装': 466,\n",
       " '鞋': 1072,\n",
       " '灰': 2424,\n",
       " '格子': 1626,\n",
       " '手提包': 843,\n",
       " '增高': 394,\n",
       " '无弹力': 529,\n",
       " '方领': 1566,\n",
       " '卡通': 2559,\n",
       " '动漫': 2557,\n",
       " '杏色': 1659,\n",
       " '大红': 253,\n",
       " '保暖': 981,\n",
       " '运动裤': 3452,\n",
       " '服饰': 2577,\n",
       " '五分袖': 246,\n",
       " '大衣': 2115,\n",
       " '白鸭绒': 856,\n",
       " '浅灰': 441,\n",
       " '3D': 419,\n",
       " '湖蓝色': 153,\n",
       " '无袖': 747,\n",
       " '金驼色': 62,\n",
       " '蓝': 3149,\n",
       " '松紧带': 315,\n",
       " '灰白色': 68,\n",
       " '可脱卸帽': 711,\n",
       " '酒红': 419,\n",
       " '绅士': 2222,\n",
       " '耐磨': 1982,\n",
       " '橘红色': 56,\n",
       " '粉红色': 630,\n",
       " '粉': 1362,\n",
       " '双排扣': 624,\n",
       " '防滑': 879,\n",
       " '靴子': 96,\n",
       " '上': 116,\n",
       " '青色': 110,\n",
       " '衬衫领': 749,\n",
       " '防水': 393,\n",
       " '短裙': 195,\n",
       " '无扣': 499,\n",
       " '黄': 1034,\n",
       " '驼色': 1260,\n",
       " '帆布': 409,\n",
       " '咖啡': 226,\n",
       " '轻薄': 588,\n",
       " 'U型领': 70,\n",
       " '标准': 135,\n",
       " '五分裤': 195,\n",
       " '橙色': 229,\n",
       " 'O型裤': 299,\n",
       " '咖啡色': 1052,\n",
       " '衬衣': 721,\n",
       " '豆绿': 132,\n",
       " '灰蓝': 53,\n",
       " '藏蓝': 221,\n",
       " '哈青': 64,\n",
       " '白兰': 60,\n",
       " '焦糖': 66,\n",
       " '背心': 645,\n",
       " '手绘': 62,\n",
       " '头层': 158,\n",
       " '雨鞋': 61,\n",
       " '灯笼裤': 451,\n",
       " '裤子': 1094,\n",
       " '深棕色': 91,\n",
       " '速干': 180,\n",
       " '藏青色': 1236,\n",
       " '锥形裤': 914,\n",
       " '灰绿色': 118,\n",
       " '深灰': 807,\n",
       " '深灰色': 945,\n",
       " '减震': 510,\n",
       " '紫': 879,\n",
       " '深蓝色': 734,\n",
       " '杏': 247,\n",
       " '蓝灰': 105,\n",
       " '棉衣': 97,\n",
       " '春': 983,\n",
       " '夏': 980,\n",
       " '米黄': 52,\n",
       " '燕麦色': 66,\n",
       " '抗冲击': 56,\n",
       " '往季': 449,\n",
       " '沙色': 147,\n",
       " '灰鸭绒': 74,\n",
       " '果绿色': 66,\n",
       " '堆堆领': 407,\n",
       " '豆绿色': 155,\n",
       " '鸭绒': 697,\n",
       " '春夏': 136,\n",
       " '白鹅绒': 75,\n",
       " '迷彩': 151,\n",
       " '皮鞋': 172,\n",
       " '蓝灰色': 249,\n",
       " '白粉': 54,\n",
       " '小': 623,\n",
       " '喇叭裤': 174,\n",
       " '浅': 467,\n",
       " '青': 580,\n",
       " '系扣': 331,\n",
       " '植物': 101,\n",
       " '花卉': 107,\n",
       " '超短裙': 77,\n",
       " '保暖裤': 528,\n",
       " '高': 460,\n",
       " '天蓝色': 140,\n",
       " '正': 181,\n",
       " '本': 81,\n",
       " '橘色': 282,\n",
       " '银色': 174,\n",
       " '黑灰色': 363,\n",
       " '九分袖': 491,\n",
       " '浅绿色': 125,\n",
       " '宝蓝': 250,\n",
       " '灰蓝色': 113,\n",
       " '棉': 305,\n",
       " '薄荷绿': 66,\n",
       " '包裹性': 53,\n",
       " '雾霾': 261,\n",
       " '军绿色': 524,\n",
       " '皮夹克': 310,\n",
       " '焦糖色': 252,\n",
       " '中裙': 303,\n",
       " '黑灰': 92,\n",
       " '煤黑色': 50,\n",
       " '工装裤': 288,\n",
       " '男': 374,\n",
       " '包': 219,\n",
       " '米黄色': 63,\n",
       " '皮粉色': 70,\n",
       " '基础': 70,\n",
       " '扣': 77,\n",
       " '大码': 809,\n",
       " '玫红': 128,\n",
       " '鹅绒': 83,\n",
       " '纯黑色': 55,\n",
       " '粉红': 145,\n",
       " '奶白色': 60,\n",
       " '刺绣': 100,\n",
       " '军绿': 319,\n",
       " '防风': 54,\n",
       " '黑白色': 343,\n",
       " '紫红色': 73,\n",
       " '套装裙': 117,\n",
       " '中国红': 112,\n",
       " '无': 94,\n",
       " '弹': 54,\n",
       " '动物': 265,\n",
       " '两': 72,\n",
       " '香槟色': 109,\n",
       " '复古': 149,\n",
       " '大红色': 145,\n",
       " '牛仔': 80,\n",
       " '西裤': 420,\n",
       " '米驼色': 74,\n",
       " '文字': 52,\n",
       " '宝蓝色': 303,\n",
       " '土黄': 63,\n",
       " '吸湿': 101,\n",
       " '排汗': 101,\n",
       " '棕': 404,\n",
       " '深驼色': 56,\n",
       " '条': 66,\n",
       " '中': 103,\n",
       " '背带裤': 50,\n",
       " '七分裤': 132,\n",
       " '玫红色': 206,\n",
       " '藏': 159,\n",
       " '魔术贴': 131,\n",
       " '短裤': 204,\n",
       " '白灰色': 66,\n",
       " '黑红色': 75,\n",
       " '白灰': 101,\n",
       " '桔红色': 81,\n",
       " '碳黑': 105,\n",
       " '蓝白色': 88,\n",
       " '涂鸦': 66,\n",
       " '深': 256,\n",
       " '雾霾蓝': 83,\n",
       " '大': 94,\n",
       " '米杏色': 83,\n",
       " '烟灰': 61,\n",
       " '兰色': 70,\n",
       " '碎花': 182,\n",
       " '深咖色': 59,\n",
       " '紧身裤': 109,\n",
       " '城市': 73,\n",
       " '姜黄': 64,\n",
       " '花': 119,\n",
       " '新': 107,\n",
       " '橘': 181,\n",
       " '灰白': 60,\n",
       " '橙': 224,\n",
       " '紫红': 95,\n",
       " '金色': 52,\n",
       " '驼': 78,\n",
       " '湖蓝': 80,\n",
       " '砖红色': 103,\n",
       " '乳白色': 74,\n",
       " '奶茶色': 51,\n",
       " '裤': 109,\n",
       " '花灰': 69,\n",
       " '姜黄色': 138,\n",
       " '枣红色': 102,\n",
       " '一粒扣': 69,\n",
       " '休闲包': 65,\n",
       " '香芋紫': 57,\n",
       " '牛角扣': 67,\n",
       " '羽绒棉': 56,\n",
       " '烟灰色': 117,\n",
       " '渐变': 75,\n",
       " '皮': 691,\n",
       " '中灰色': 86,\n",
       " '秋冬': 87,\n",
       " '超短款': 145,\n",
       " '吊带': 386,\n",
       " '呢': 58,\n",
       " '橄榄绿': 69,\n",
       " '米驼': 76,\n",
       " '几何': 51,\n",
       " '图案': 60,\n",
       " '毛呢': 222,\n",
       " '褐色': 56,\n",
       " '圆点': 65,\n",
       " '呢子': 372,\n",
       " '红棕色': 88,\n",
       " '马夹': 148,\n",
       " '领': 64,\n",
       " '银': 189,\n",
       " '纯白色': 74,\n",
       " '男裤': 279,\n",
       " '加': 317,\n",
       " '绒': 93,\n",
       " '长裙': 99,\n",
       " '金': 259,\n",
       " '枣红': 93,\n",
       " '浅棕色': 64,\n",
       " '纯': 53,\n",
       " '传奇': 73,\n",
       " '女': 173,\n",
       " '土黄色': 56,\n",
       " '呢大衣': 114,\n",
       " '经典': 107,\n",
       " '浅绿': 74,\n",
       " '浅紫色': 73,\n",
       " '兰': 460,\n",
       " '西装裤': 406,\n",
       " '格': 78,\n",
       " '毛呢外套': 110,\n",
       " '咖': 348,\n",
       " '九分': 124,\n",
       " '套装': 90,\n",
       " '吊带型': 421,\n",
       " '不加绒': 214,\n",
       " '毛领': 59,\n",
       " '吊带衫': 143,\n",
       " '单件': 64,\n",
       " '貂皮': 107,\n",
       " '内衣': 142,\n",
       " '加绒款': 96,\n",
       " '背带': 169,\n",
       " '底': 55,\n",
       " '直筒': 81,\n",
       " '色调': 68,\n",
       " '束脚': 72,\n",
       " '皮外套': 79,\n",
       " '件': 73,\n",
       " '春秋': 166,\n",
       " '不': 54,\n",
       " '单': 73,\n",
       " '修身裤': 55,\n",
       " '褐': 67,\n",
       " '啡': 84}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45000it [08:51, 84.60it/s]\n"
     ]
    }
   ],
   "source": [
    "# 生成分好的title词集\n",
    "fine_file = 'data/train/fine45000.txt'\n",
    "save_fine_file = 'data/train/fine45000_OnlySplit.txt'\n",
    "rets = []\n",
    "i = 0\n",
    "with open(fine_file, 'r') as f:\n",
    "    for line in tqdm(f):\n",
    "        new_item = {}\n",
    "        item = json.loads(line)\n",
    "        segment, _ = ltp.seg([item['title']])\n",
    "        for word in segment[0]:\n",
    "            word = word.upper() # 字母统一为大写\n",
    "        new_item['title_split'] = segment[0]\n",
    "        # 更改保存的顺序，便于查看\n",
    "        rets.append(json.dumps(new_item, ensure_ascii=False)+'\\n')\n",
    "        \n",
    "        # if i>20000:\n",
    "        #     break\n",
    "        # i += 1\n",
    "        \n",
    "with open(save_fine_file, 'w') as f:\n",
    "    f.writelines(rets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [00:06, 80.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# 生成分好的title词集\n",
    "fine_file = 'data/train/fine45000.txt'\n",
    "save_fine_file = 'data/train/fine45000_Sample.txt'\n",
    "rets = []\n",
    "i = 0\n",
    "with open(fine_file, 'r') as f:\n",
    "    for line in tqdm(f):\n",
    "        item = json.loads(line)\n",
    "        segment, _ = ltp.seg([item['title']])\n",
    "        for word in segment[0]:\n",
    "            word = word.upper() # 字母统一为大写\n",
    "        item['title_split'] = segment[0]\n",
    "        # 更改保存的顺序，便于查看\n",
    "        feature = item['feature']\n",
    "        del item['feature']\n",
    "        item['feature'] = feature\n",
    "        rets.append(json.dumps(item, ensure_ascii=False)+'\\n')\n",
    "        \n",
    "        if i>500:\n",
    "            break\n",
    "        i += 1\n",
    "        \n",
    "with open(save_fine_file, 'w') as f:\n",
    "    f.writelines(rets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "89588it [19:08, 78.03it/s]\n"
     ]
    }
   ],
   "source": [
    "coarse_file = 'data/train/coarse89588.txt'\n",
    "save_coarse_file = 'data/train/coarse89588_S.txt'\n",
    "rets = []\n",
    "i = 0\n",
    "with open(coarse_file, 'r') as f:\n",
    "    for line in tqdm(f):\n",
    "        item = json.loads(line)\n",
    "        segment, _ = ltp.seg([item['title']])\n",
    "        for word in segment[0]:\n",
    "            word = word.upper() # 字母统一为大写\n",
    "        item['title_split'] = segment[0]\n",
    "        # 更改保存的顺序，便于查看\n",
    "        feature = item['feature']\n",
    "        del item['feature']\n",
    "        item['feature'] = feature\n",
    "        rets.append(json.dumps(item, ensure_ascii=False)+'\\n')\n",
    "        \n",
    "        # if i>500:\n",
    "        #     break\n",
    "        # i += 1\n",
    "\n",
    "with open(save_coarse_file, 'w') as f:\n",
    "    f.writelines(rets)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ab7a9148291449fc4391f360f086843f6cf18b6c2df8af6702dacf91b204e632"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
