{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "fine_path = 'data/train_fine.txt'\n",
    "dic = set()\n",
    "count = 1\n",
    "l = 0\n",
    "with open(fine_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        data = json.loads(line)\n",
    "        l = max(0, len(data['title']))\n",
    "        for key in data['key_attr']:\n",
    "            if key not in dic:\n",
    "                dic.add(key)\n",
    "                count += 1\n",
    "\n",
    "print(key)\n",
    "print(dic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import json\n",
    "key_dic = {}\n",
    "i = 0\n",
    "with open('data/attr_to_attrvals.json', 'r', encoding='utf-8') as f:\n",
    "    key_attr = json.load(f)\n",
    "    for key in key_attr:\n",
    "        key_dic[key] = i\n",
    "        i += 1\n",
    "print(key_dic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "import copy\n",
    "\n",
    "data_path_1 = './data/train_fine.txt'\n",
    "data_path_2 = './data/train_coarse.txt'\n",
    "\n",
    "data_pos_list = []\n",
    "data_neg_list = []\n",
    "\n",
    "with open(data_path_1, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        data = json.loads(line)\n",
    "        if data['match']['图文'] == 1:\n",
    "            data_pos_list.append(data)\n",
    "        else:\n",
    "            data_neg_list.append(data)\n",
    "\n",
    "with open(data_path_2, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        data = json.loads(line)\n",
    "        if data['match']['图文'] == 1:\n",
    "            data_pos_list.append(data)\n",
    "        else:\n",
    "            data_neg_list.append(data)\n",
    "\n",
    "new_neg_list = []\n",
    "for i in range(len(data_pos_list)):\n",
    "    dic = copy.deepcopy(data_pos_list[i])\n",
    "    index = random.randint(0, len(data_pos_list)-1)\n",
    "    while index == i:\n",
    "        index = random.randint(0, len(data_pos_list)-1)\n",
    "    dic['title'] = data_pos_list[index]['title']\n",
    "    dic['match']['图文'] = 0\n",
    "    new_neg_list.append(dic)\n",
    "\n",
    "print(len(data_pos_list), len(data_neg_list), len(new_neg_list))\n",
    "all_data = data_pos_list + data_neg_list + new_neg_list\n",
    "np.random.shuffle(all_data)\n",
    "l = int(len(all_data) * 0.9)\n",
    "x_train_list = all_data[:l]\n",
    "x_val_list = all_data[l:]\n",
    "# np.random.shuffle(x_val_list)\n",
    "\n",
    "x_train_list = [json.dumps(dic, ensure_ascii=False)+'\\n' for dic in x_train_list]\n",
    "x_val_list = [json.dumps(dic, ensure_ascii=False)+'\\n' for dic in x_val_list]\n",
    "\n",
    "\n",
    "# with open('./data/pretrain_match.txt', 'w', encoding='utf-8') as f:\n",
    "#     f.writelines(pre_ret)\n",
    "\n",
    "with open('./data/new_train_match.txt', 'w', encoding='utf-8') as f:\n",
    "    f.writelines(x_train_list)\n",
    "\n",
    "with open('./data/new_val_match.txt', 'w', encoding='utf-8') as f:\n",
    "    f.writelines(x_val_list)\n",
    "\n",
    "# print(len(pre_ret))\n",
    "print(len(x_train_list))\n",
    "print(len(x_val_list))\n",
    "print(len(x_train_list) + len(x_val_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "new_dic = {}\n",
    "\n",
    "with open('./data/attr_to_attrvals.json', 'r', encoding='utf-8') as f:\n",
    "    attr_key = json.load(f)\n",
    "    for key, value in attr_key.items():\n",
    "        tmp = []\n",
    "        for v in value:\n",
    "            if '=' in v:\n",
    "                tmp.append(v.split('='))\n",
    "            else:\n",
    "                tmp.append([v])\n",
    "        new_dic[key] = tmp\n",
    "print(new_dic)\n",
    "rets = [json.dumps(new_dic, ensure_ascii=False)+'\\n']\n",
    "with open('./data/attr_match.json', 'w', encoding='utf-8') as f:\n",
    "    f.writelines(rets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88679/88679 [02:45<00:00, 536.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YES\n",
      "yes\n",
      "88679\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "not_math_list = []\n",
    "from random import choice\n",
    "\n",
    "with open('./data/attr_match.json', 'r', encoding='utf-8') as f:\n",
    "    attr_key = json.load(f)\n",
    "\n",
    "def get_title_mask(title, key, val, attr_key):\n",
    "    values = attr_key[key]\n",
    "    key_index = 0\n",
    "    for i in range(len(values)):\n",
    "        if val in values[i]:\n",
    "            key_index = i\n",
    "            break\n",
    "    new_index = np.random.randint(len(values))\n",
    "    while new_index == key_index:\n",
    "        new_index = np.random.randint(len(values))\n",
    "    sub_val = values[new_index]\n",
    "    new_sub_val = sub_val[np.random.randint(len(sub_val))]\n",
    "\n",
    "    return title.replace(val, new_sub_val, 1)\n",
    "\n",
    "def get_random_key(keys, ratio=0.7):\n",
    "    list_ratio = [0.7, 0.9, 1]\n",
    "    ratio = choice(list_ratio)\n",
    "    l = int(len(keys) * ratio)\n",
    "    if l == 0:\n",
    "        l = 1\n",
    "    np.random.shuffle(keys)\n",
    "    return keys[:l]\n",
    "\n",
    "count = 0\n",
    "with open('./data/pos_coarse.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    new_dic = {}\n",
    "    for line in tqdm(lines):\n",
    "        data = json.loads(line)\n",
    "        new_dic = data\n",
    "        #print(new_dic['title'])\n",
    "        keys = get_random_key([x for x in new_dic['match'].keys() if x != '图文'])\n",
    "        for key in keys:\n",
    "            new_dic['title'] = get_title_mask(new_dic['title'], key, new_dic['key_attr'][key], attr_key)\n",
    "            new_dic['match'][key] = 0\n",
    "        new_dic['match']['图文'] = 0\n",
    "        #print(new_dic['title'])\n",
    "        not_math_list.append(json.dumps(new_dic, ensure_ascii=False)+'\\n')\n",
    "        # print(new_dic['match'])\n",
    "        # count += 1\n",
    "        # print(count)\n",
    "    print('YES')\n",
    "print('yes')\n",
    "print(len(not_math_list))       \n",
    "with open('./data/neg_coarse.txt', 'w', encoding='utf-8') as f:\n",
    "    f.writelines(not_math_list)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(not_math_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "not_math_list = []\n",
    "from random import choice\n",
    "\n",
    "with open('./data/attr_match.json', 'r', encoding='utf-8') as f:\n",
    "    attr_key = json.load(f)\n",
    "\n",
    "def get_title_mask(title, key, val, attr_key):\n",
    "    values = attr_key[key]\n",
    "    key_index = 0\n",
    "    for i in range(len(values)):\n",
    "        if val in values[i]:\n",
    "            key_index = i\n",
    "            break\n",
    "    new_index = np.random.randint(len(values))\n",
    "    while new_index == key_index:\n",
    "        new_index = np.random.randint(len(values))\n",
    "    sub_val = values[new_index]\n",
    "    new_sub_val = sub_val[np.random.randint(len(sub_val))]\n",
    "\n",
    "    return title.replace(val, new_sub_val, 1)\n",
    "\n",
    "def get_random_key(keys, ratio=0.7):\n",
    "    list_ratio = [0.7, 0.9, 1]\n",
    "    ratio = choice(list_ratio)\n",
    "    l = int(len(keys) * ratio)\n",
    "    if l == 0:\n",
    "        l = 1\n",
    "    np.random.shuffle(keys)\n",
    "    return keys[:l]\n",
    "\n",
    "count = 0\n",
    "with open('./data/pos_coarse.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    new_dic = {}\n",
    "    for line in tqdm(lines):\n",
    "        data = json.loads(line)\n",
    "        new_dic = data\n",
    "        keys = get_random_key([x for x in new_dic['match'].keys() if x != '图文'])\n",
    "        for key in keys:\n",
    "            new_dic['title'] = get_title_mask(new_dic['title'], key, new_dic['key_attr'][key], attr_key)\n",
    "            new_dic['match'][key] = 0\n",
    "        new_dic['match']['图文'] = 0\n",
    "        not_math_list.append(json.dumps(new_dic, ensure_ascii=False)+'\\n')\n",
    "        \n",
    "    print('YES')\n",
    "print('yes')\n",
    "print(len(not_math_list))       \n",
    "with open('./data/neg_coarse.txt', 'w', encoding='utf-8') as f:\n",
    "    f.writelines(not_math_list)\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac71fce329e590cf60d05e85f1e361b3138a1b17dd586b9aaebfc1dd7e1fc45f"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('open_clip')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
